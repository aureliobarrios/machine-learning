{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Algorithm\n",
    "\n",
    "Building a validation algorithm.\n",
    "\n",
    "### Part 1: Reddit Confidence Score\n",
    "\n",
    "We use Reddits ranking score to get a confidence score of current voting scenarios for a resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint, seed\n",
    "\n",
    "def confidence(ups, downs, confidence_score=0.90):\n",
    "    #measure the total number of ratings\n",
    "    n = ups + downs\n",
    "    #what to do when there are no ratings\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    # finding the (1- confidence / 2) quantile of the standard normal distribution\n",
    "    z = norm.ppf(1 - ((1 - confidence_score) / 2))\n",
    "    #find the observed fraction of positive ratings\n",
    "    p = ups / n\n",
    "    #use Wilsons score interval to find the lower bound, essentially trying to answer\n",
    "    # Given the ratings I have, there is a 80% chance (based on confidence score) that the\n",
    "    # \"real\" fraction of positive ratings is at least what?\n",
    "    #     we want the lower bound therefore only calculating that portion of formula\n",
    "    #Calculate the left side of formula\n",
    "    left_side = p + 1/(2*n)*z*z\n",
    "    #Calculate the right side of formula\n",
    "    right_side = z*sqrt(p*(1-p)/n + z*z/(4*n*n))\n",
    "    #Calculate the bottom side of formula\n",
    "    under = 1+1/n*z*z\n",
    "    #return lower bound of score\n",
    "    return (left_side - right_side) / under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example voting scenario for a resource\n",
    "upvotes = 14\n",
    "downvotes = 2\n",
    "\n",
    "print(f\"Confidence for this scenario: {confidence(upvotes, downvotes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Implementing Decay Rate (Over Time)\n",
    "\n",
    "In this step we implement a decay rate $\\lambda$ that controls how the score is affected over time. We also want the rate of decay over time to be at a constant rate, so in order to do this we must use the exponential function. The exponential function helps ensure that time affects the score gradually and naturally as time passes.\n",
    "\n",
    "Decay rate must be negative to ensure that we are measuring exponential decay rather than exponential growth.\n",
    "$$score = p^\\alpha * e^{-\\lambda t}$$\n",
    "\n",
    "We also include an $\\alpha$ value to the reddit confidence score that measures the weight of that value in regards to the final score. Consider a sceneario where we have a resource with a confidence rating of 0.9 from the reddit step, we will see how changing the $\\alpha$ state impacts the score over the course of 1 day.\n",
    "\n",
    "|  | $\\alpha = 0.8$ | $\\alpha = 1$ | $\\alpha = 1.2$ |\n",
    "| :--:| :---: | :---: | :---: |\n",
    "| score | 0.91125 | 0.89225 | 0.87365 |\n",
    "\n",
    "\n",
    "#### How Decay Rate Affects Scores Over Time\n",
    "\n",
    "Consider a scenario where a resources has a perfect score: $p = 1$. This is how time will affect that score with different decay rates.\n",
    "\n",
    "| Time (Days) | $\\lambda = 10^{-5}$ | $\\lambda = 10^{-6}$ | $\\lambda = 10^{-7}$ |\n",
    "| :---------: | :-----------------: | :-----------------: | :-----------------: |\n",
    "| 1 Day (86400s) | 0.406 | 0.913 | 0.991 |\n",
    "| 3 Days (259200s) | 0.049 | 0.590 | 0.974 |\n",
    "| 7 Days (604800s) | 0.0009 | 0.239 | 0.954 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "#build an updated score version\n",
    "def score_v_one(upvotes, downvotes, time, alpha=0.8):\n",
    "    #get the reddit confidence score\n",
    "    p = confidence(upvotes, downvotes)\n",
    "    #calculate p^alpha\n",
    "    confidence_score = p ** alpha\n",
    "    #calculate time part\n",
    "    time_decay = exp(-(10**(-7))*time)\n",
    "    return confidence_score * time_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of upvotes for a resource\n",
    "upvotes = 20\n",
    "#number of downvotes for a resource\n",
    "downvotes = 2\n",
    "#the time the resources has been up\n",
    "days = 3\n",
    "#time in seconds for formula\n",
    "seconds = days * 86400\n",
    "\n",
    "print(f\"Score: {score_v_one(upvotes, downvotes, seconds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Algo Formula\n",
    "\n",
    "$$score = p^{0.8} \\cdot e^{-10^{-7} \\cdot t}$$\n",
    "\n",
    "With a **validation threshold** of 0.65, which allows for a solid amount of resources to be used for training.\n",
    "\n",
    "Where:\n",
    "- $p$ is the confidence score received from Reddits ranking formula, calculated using **upvotes** and **downvotes**\n",
    "- The value 0.8 allows for the confidence score to be weighed slightly more than time, in order to allow for good resources scores to be preserved more throughout time\n",
    "- $e^{-10^{-7} \\cdot t}$ allows for a solid decay rate that will preserve resources for a longer period of time\n",
    "\n",
    "\n",
    "\n",
    "### Future Iterations of Formula\n",
    "\n",
    "In the future if we want to include different variables into the formula, we could include those proportions like so.\n",
    "\n",
    "For example, if we want to factor in the proportion of views to total users. The formula would look like this:\n",
    "\n",
    "$$score = p^{0.8} \\cdot v^{\\beta} \\cdot e^{-10^{-7} \\cdot t}$$\n",
    "\n",
    "Where:\n",
    "- $v$ is the proportion of views / total users\n",
    "- $\\beta$ is the weight we would want to associate to the views proportion parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build future iteration of score\n",
    "def score_v_two(upvotes, downvotes, views, total_users, time, alpha=0.8, beta=0.05, delta=7):\n",
    "    #get the reddit confidence score\n",
    "    p = confidence(upvotes, downvotes)\n",
    "    #calculate p^alpha\n",
    "    confidence_score = p ** alpha\n",
    "    #calculate viewership portion\n",
    "    engagement = (views / total_users) ** beta\n",
    "    #calculate time part\n",
    "    time_decay = exp(-(10**(-delta))*time)\n",
    "    return confidence_score * engagement * time_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of views\n",
    "views = 40\n",
    "#number of total users\n",
    "total_users = 200\n",
    "\n",
    "print(f\"Updated Score: {score_v_two(upvotes, downvotes, views, total_users, seconds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Formula With Engagement\n",
    "\n",
    "$$score = p^{0.8} \\cdot v^{0.05} \\cdot e^{-10^{-7}\\cdot t}$$\n",
    "\n",
    "Where:\n",
    "- $p$ is the confidence score given by the reddit algorithm, calculated using upvotes and downvotes\n",
    "- $v$ measures the engagement or proportion of views / total users\n",
    "- $e^{-10^{-7}\\cdot t}$ measures the time decay of the resource\n",
    "\n",
    "### Visualizing Distribution Of Scores From Simulated Scenarios\n",
    "\n",
    "Simulated random scenarios to see how the score is distributed in order to arrive at a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducability\n",
    "seed(42)\n",
    "#build data list\n",
    "data = []\n",
    "#build rows of data\n",
    "for i in range(10000):\n",
    "    #get random upvote\n",
    "    random_upvote = randint(1, 100)\n",
    "    #get random downvote\n",
    "    random_downvote = randint(1, 100)\n",
    "    #get random day\n",
    "    random_day = randint(1, 90)\n",
    "    #calculate the seconds\n",
    "    curr_seconds = random_day * 86400\n",
    "    #get random views\n",
    "    random_views = randint(1, 200)\n",
    "    #get the score for current random scenario\n",
    "    curr_score = score_v_two(random_upvote, random_downvote, random_views, 200, curr_seconds)\n",
    "    #append data to list\n",
    "    data.append([random_upvote, random_downvote, random_day, random_views, curr_score])\n",
    "\n",
    "#build dataframe\n",
    "df = pd.DataFrame(data, columns=[\"upvotes\", \"downvotes\", \"days\", \"views\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below the highest score was 0.924 and the lowest score was 0.003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sorted values\n",
    "df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calcuate the percentiles, we found that:\n",
    "- 90% of the scores were below 0.549\n",
    "- 95% of the scores were below 0.628."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the score for 90th percentile\n",
    "print(f\"90th percentile score: {df.score.quantile(0.9)}\")\n",
    "#get the score for 95th percentile\n",
    "print(f\"95th percentile score: {df.score.quantile(0.95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the box plot of scores\n",
    "sns.boxplot(x=df[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the stats of the boxplot for original simulated scores\n",
    "box_stats = boxplot_stats(df[\"score\"])\n",
    "#get the lower whisker score\n",
    "print(f\"Lower Whisker: {box_stats[0][\"whislo\"]}\")\n",
    "#get the upper whisker score\n",
    "print(f\"Upper Whisker: {box_stats[0][\"whishi\"]}\")\n",
    "#get all rows excluding outliers\n",
    "df_no_outliers = df[df[\"score\"] <= box_stats[0][\"whishi\"]]\n",
    "#calculate the 95th percentile for scores excluding outliers\n",
    "print(f\"95th percentile (excluding outliers): {df_no_outliers[\"score\"].quantile(0.95)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histrogram of the distribution of scores with a red line at the 95 percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the distribution of scores\n",
    "sns.histplot(data=df, x=\"score\", bins=np.arange(0, 1, 0.1))\n",
    "\n",
    "plt.axvline(df_no_outliers[\"score\"].quantile(0.95), color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the outlier scores\n",
    "df_outliers = df[df[\"score\"] > box_stats[0][\"whishi\"]]\n",
    "#see the results\n",
    "df_outliers.sort_values(by=[\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key TakeAways\n",
    "- If downvotes > upvotes then score will be less than .50\n",
    "- Most scores (around 95%) will fall below 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to run the same simulation but changing the weights of the variables to see how the distribution of the scores changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducability\n",
    "seed(42)\n",
    "#build data list\n",
    "data_two = []\n",
    "#build rows of data\n",
    "for i in range(10000):\n",
    "    #get random upvote\n",
    "    random_upvote = randint(1, 25)\n",
    "    #get random downvote\n",
    "    random_downvote = randint(1, 25)\n",
    "    #get random day\n",
    "    random_day = randint(1, 90)\n",
    "    #calculate the seconds\n",
    "    curr_seconds = random_day * 86400\n",
    "    #get random views\n",
    "    random_views = randint(1, 200)\n",
    "    #get the score for current random scenario\n",
    "    curr_score = score_v_two(random_upvote, random_downvote, random_views, 200, curr_seconds)\n",
    "    #append data to list\n",
    "    data_two.append([random_upvote, random_downvote, random_day, random_views, curr_score])\n",
    "\n",
    "#build dataframe\n",
    "df_two = pd.DataFrame(data_two, columns=[\"upvotes\", \"downvotes\", \"days\", \"views\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the score for 90th percentile\n",
    "print(f\"90th percentile score: {df_two.score.quantile(0.9)}\")\n",
    "#get the score for 95th percentile\n",
    "print(f\"95th percentile score: {df_two.score.quantile(0.95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the box plot of scores\n",
    "sns.boxplot(x=df_two[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the stats of the boxplot for original simulated scores\n",
    "box_stats_two = boxplot_stats(df_two[\"score\"])\n",
    "#get the outlier scores\n",
    "df_two_outliers = df_two[df_two[\"score\"] > box_stats_two[0][\"whishi\"]]\n",
    "#see the results\n",
    "df_two_outliers.sort_values(by=[\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the distribution of scores\n",
    "sns.histplot(data=df_two, x=\"score\", bins=np.arange(0, 1, 0.1))\n",
    "\n",
    "plt.axvline(df_two.score.quantile(0.95), color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
