{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Algorithm Explained\n",
    "\n",
    "Notebook working through an example of how Reddit sorts their comments. \n",
    "\n",
    "### Confidence Sort Using Wilson's Score Interval - For Comment Ranking\n",
    "\n",
    "**Goal:** Rank the best comments highest regardless of their submission time (time was originally used in the main Reddit page algorithm which is different than the comment sorting found here) \n",
    "\n",
    "The confidence sort treats the vote count as a statistical sampling of a hypothetical full vote by everyone. You can think about this way: \n",
    "- \"Given the ratings that I currently have, there is a 80% chance (based on your chosen confidence score) that the 'real' fraction of positive ratings is **at least** what?\n",
    "\n",
    "The algorithm then uses the **lower bound** of the Wilson score to find this fraction, using the formula below. \n",
    "\n",
    "![Wilson Formula](../notebooks/images/wilson-formula.png)\n",
    "\n",
    "Essentially the confidence sort is giving the comment a provisional ranking that it is 80% (based on your confidence score) sure that it will get to. If a comment has 1 upvote and zero downvotes, although it has a 100% upvote rate since there is not much data the algorithm will keep it near the bottom. But if it has 10 upvotes and 1 downvote then the system will have enough confidence to place it above something with 40 upvotes and 20 downvotes - with the logic being that by the time this comment has gotten 40 upvotes it will have less than 20 downvotes. The algorithm also has the capability to offset when it is wrong (20% of the time according to our confidence score) since it will push the comment with less data to the top allowing for the chance to collect more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "def confidence(ups, downs):\n",
    "    #measure the total number of ratings\n",
    "    n = ups + downs\n",
    "    #what to do when there are no ratings\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    #this is saying that we have a 80% chance of finding the real fraction of ratings\n",
    "    confidence_score = .80\n",
    "    # finding the (1- confidence / 2) quantile of the standard normal distribution\n",
    "    z = norm.ppf(1 - ((1 - confidence_score) / 2))\n",
    "    #find the observed fraction of positive ratings\n",
    "    p = ups / n\n",
    "    #use Wilsons score interval to find the lower bound, essentially trying to answer\n",
    "    # Given the ratings I have, there is a 80% chance (based on confidence score) that the\n",
    "    # \"real\" fraction of positive ratings is at least what?\n",
    "    #     we want the lower bound therefore only calculating that portion of formula\n",
    "    #Calculate the left side of formula\n",
    "    left_side = p + 1/(2*n)*z*z\n",
    "    #Calculate the right side of formula\n",
    "    right_side = z*sqrt(p*(1-p)/n + z*z/(4*n*n))\n",
    "    #Calculate the bottom side of formula\n",
    "    under = 1+1/n*z*z\n",
    "    #return lower bound of score\n",
    "    return (left_side - right_side) / under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
