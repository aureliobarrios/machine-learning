{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers From Scratch\n",
    "\n",
    "Notebook where I build a Transformer from scratch using PyTorch neural networks.\n",
    "\n",
    "### Read In Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in shakespear input file\n",
    "with open('../notebooks/data/input.txt', 'r', encoding = 'utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#get all the unique characters that occur in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mapping of characters to integers\n",
    "string_to_integer = {ch: i for i, ch in enumerate(chars)}\n",
    "#create a mapping of integers to characters\n",
    "integer_to_string = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding our initial text into a PyTorch tensor using our simple encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build simple encoder that takes a string and outputs a list of integers\n",
    "encoder = lambda input_string: [string_to_integer[character] for character in input_string]\n",
    "#build a simple decoder that takes a list of integers, and outputs a string\n",
    "decoder = lambda input_list: ''.join([integer_to_string[integer] for integer in input_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#encode entire text dataset and store it into a torch.Tensor\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first 90% characters\n",
    "n = int(0.9 * len(data))\n",
    "#splitting our dataset into training and validation sets for future use\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make batches for training\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is: 47\n",
      "when input is tensor([18, 47]) the target is: 56\n",
      "when input is tensor([18, 47, 56]) the target is: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "#training visualizer\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "#see training inputs\n",
    "for trial in range(block_size):\n",
    "    context = x[:trial+1]\n",
    "    target = y[trial]\n",
    "    print(f\"when input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have visualized how batching will work we will create some batch dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for replication\n",
    "torch.manual_seed(1337)\n",
    "#the number of batches used for training\n",
    "batch_size = 4\n",
    "#the maximum context length for predictions\n",
    "block_size = 8\n",
    "\n",
    "#function that generates batches\n",
    "def get_batch(split):\n",
    "    #differentiate between training and validation\n",
    "    if split == \"train\":\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = val_data\n",
    "    #getting random indices between data for sampling of batches\n",
    "    random_index = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    #sampling batches and stacking them to same dimension\n",
    "    x = torch.stack([data[index:index+block_size] for index in random_index])\n",
    "    #sampling batches for target variable\n",
    "    y = torch.stack([data[index+1:index+block_size+1] for index in random_index])\n",
    "    return x, y\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
